{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f969b1b-ae9d-485f-a756-9aaf52e91e2a",
   "metadata": {},
   "source": [
    "# Team Octopus: Pipeline Skeleton\n",
    "### This is the pseudocode for our pipeline plan for the RDMF surge hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c20088-51c4-4771-b7fd-5ef89c1b2f1b",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340ef8d1-2dad-42db-a983-f8504c2ddc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cryptography.fernet import Fernet\n",
    "from datetime import datetime\n",
    "from utils import Logger\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e52b8f-16ce-4ecf-948f-df05cfd2850c",
   "metadata": {},
   "source": [
    "### Log info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5a3b0-6e34-460f-848b-972c253e2e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = Logger(\"EncryptionLogger\").get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d3f78-3749-4e76-89f9-3a558534cf0f",
   "metadata": {},
   "source": [
    "### Class to generate salt from today's date and customer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f881b7d4-4771-4d92-a4f5-c59841e33232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaltGenerator:\n",
    "    def generate_salt(self, customer_name):\n",
    "        today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        salt = f\"{today_date}_{customer_name}\"\n",
    "        return salt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ad375-f906-4933-9501-c43c78853348",
   "metadata": {},
   "source": [
    "### Class to encrypt a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67e84604-70e9-4d93-a76e-38836fd4693f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnEncryptor:\n",
    "    def __init__(self, salt):\n",
    "        self.salt = salt\n",
    "\n",
    "    def encrypt_value_with_salt(self, value):\n",
    "        cipher_suite = Fernet(Fernet.generate_key())\n",
    "        value_with_salt = value + self.salt\n",
    "        encrypted_value = cipher_suite.encrypt(value_with_salt.encode())\n",
    "        return encrypted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629820c1-c61d-4150-b99f-1dadbaeb0f88",
   "metadata": {},
   "source": [
    "### Encrypted Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7268fedc-ae60-4d34-b258-1edb30e3a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedDataset:\n",
    "    def __init__(self, bucket_name, file_name, column_name, salt_generator, column_encryptor):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.file_name = file_name\n",
    "        self.column_name = column_name\n",
    "        self.salt_generator = salt_generator\n",
    "        self.column_encryptor = column_encryptor\n",
    "        self.dataset = pd.read_csv(f\"gs://{self.bucket_name}/{self.file_name}\")\n",
    "    \n",
    "    def encrypt_column_with_salt(self, df):\n",
    "        selected_column = self.dataset[self.column_name].astype(str)\n",
    "        encrypted_values = []\n",
    "        \n",
    "        df = self.dataset\n",
    "        \n",
    "        for value in selected_column:\n",
    "            value = self.column_encryptor.encrypt_value_with_salt(value)\n",
    "            encrypted_values.append(value)\n",
    "            \n",
    "        df[\"encrypted_id\"] = encrypted_values\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132a317-f466-4377-a5c6-ff9bf9ea70e8",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "462b82f0-17ab-4f52-a201-acbf1891a906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "salt_generator = SaltGenerator()\n",
    "salt = salt_generator.generate_salt(\"some_customer\")\n",
    "print(type(salt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03b4d20d-0fc1-4dac-95b8-619b8005cf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_encryptor = ColumnEncryptor(salt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "833290d4-cf1c-4e12-a41f-e56e6b0bea0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = EncryptedDataset(\"rdmf_mock_data\", \"BI_mockdata.csv\", \"BI_ID\", salt_generator, column_encryptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55b607fe-5409-4695-8fd9-a22becd49b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed = dataset.encrypt_column_with_salt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df1cfc13-7d2c-47c5-b4f8-38251cafac1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_ID</th>\n",
       "      <th>Business_name</th>\n",
       "      <th>PAYE_scheme_ref</th>\n",
       "      <th>SIC_code</th>\n",
       "      <th>UPRN</th>\n",
       "      <th>encrypted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606162501213544</td>\n",
       "      <td>Infinidum Enterprises</td>\n",
       "      <td>100000</td>\n",
       "      <td>25143</td>\n",
       "      <td>950187498346</td>\n",
       "      <td>b'gAAAAABl6SN4TRlirAu8M5dB21m_QqPDDm0SGJfybQn7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>606948361742718</td>\n",
       "      <td>Nitzsche PLC</td>\n",
       "      <td>100001</td>\n",
       "      <td>55303</td>\n",
       "      <td>950698168954</td>\n",
       "      <td>b'gAAAAABl6SN4HOepbXQ7Ssk8SB4zCtwgVIlXqeNXFDdp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>606089685526234</td>\n",
       "      <td>Schamberger-Smith</td>\n",
       "      <td>100002</td>\n",
       "      <td>52512</td>\n",
       "      <td>950320937277</td>\n",
       "      <td>b'gAAAAABl6SN4DcZZNkbiNSBp1yc38gucCz6r3OAwGCsI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606885102242594</td>\n",
       "      <td>Heidenreich-Schimmel</td>\n",
       "      <td>100003</td>\n",
       "      <td>68588</td>\n",
       "      <td>950186421264</td>\n",
       "      <td>b'gAAAAABl6SN4V_8fYzt1QRmEWtBop6VcH2WV_f2q1iZE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606517518834848</td>\n",
       "      <td>Turner, Davis and Weber</td>\n",
       "      <td>100004</td>\n",
       "      <td>85252</td>\n",
       "      <td>950680091532</td>\n",
       "      <td>b'gAAAAABl6SN41ri3KYvw86xiPr8dd53sGijA8FvdyQXS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BI_ID            Business_name  PAYE_scheme_ref  SIC_code  \\\n",
       "0  606162501213544    Infinidum Enterprises           100000     25143   \n",
       "1  606948361742718             Nitzsche PLC           100001     55303   \n",
       "2  606089685526234        Schamberger-Smith           100002     52512   \n",
       "3  606885102242594     Heidenreich-Schimmel           100003     68588   \n",
       "4  606517518834848  Turner, Davis and Weber           100004     85252   \n",
       "\n",
       "           UPRN                                       encrypted_id  \n",
       "0  950187498346  b'gAAAAABl6SN4TRlirAu8M5dB21m_QqPDDm0SGJfybQn7...  \n",
       "1  950698168954  b'gAAAAABl6SN4HOepbXQ7Ssk8SB4zCtwgVIlXqeNXFDdp...  \n",
       "2  950320937277  b'gAAAAABl6SN4DcZZNkbiNSBp1yc38gucCz6r3OAwGCsI...  \n",
       "3  950186421264  b'gAAAAABl6SN4V_8fYzt1QRmEWtBop6VcH2WV_f2q1iZE...  \n",
       "4  950680091532  b'gAAAAABl6SN41ri3KYvw86xiPr8dd53sGijA8FvdyQXS...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658f429-42ec-4d14-9f0b-e15def8a3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName('rdmf_encryption')\n",
    "         .master('yarn')\n",
    "         .config('spark.driver.maxResultSize','2g')\n",
    "         .config('spark.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711d619e-a2ee-41b0-8d84-9f9a72512df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyspark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_bigquery\u001b[39m(\n\u001b[0;32m----> 2\u001b[0m     df: \u001b[43mpyspark\u001b[49m\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      3\u001b[0m     table: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      4\u001b[0m     project: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     schema: pyspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mStructType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Save a PySpark DataFrame to BigQuery.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pyspark' is not defined"
     ]
    }
   ],
   "source": [
    "def save_to_bigquery(\n",
    "    df: pyspark.sql.DataFrame,\n",
    "    table: str,\n",
    "    project: str = None,\n",
    "    mode: str = \"append\",\n",
    "    schema: pyspark.sql.types.StructType = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save a PySpark DataFrame to BigQuery.\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.DataFrame): DataFrame to save.\n",
    "        table (str): Name of the BigQuery table to save to.\n",
    "        project (str, optional): BigQuery project to save to. Defaults to the project associated with the Spark context.\n",
    "        mode (str, optional): Write mode. One of \"append\", \"overwrite\", or \"ignore\". Defaults to \"append\".\n",
    "        schema (pyspark.sql.types.StructType, optional): Schema of the DataFrame. If not provided, it will be inferred from the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if project is None:\n",
    "        project = df.sql_ctx.sparkSession._jsc.hadoopConfiguration().get(\"fs.gs.project.id\")\n",
    "\n",
    "    if schema is None:\n",
    "        schema = df.schema\n",
    "\n",
    "    df.write \\\n",
    "        .format(\"bigquery\") \\\n",
    "        .option(\"temporaryGcsBucket\", \"YOUR_GCS_BUCKET_NAME\") \\\n",
    "        .option(\"table\", table) \\\n",
    "        .option(\"project\", project) \\\n",
    "        .option(\"writeDisposition\", mode) \\\n",
    "        .schema(schema) \\\n",
    "        .save()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
